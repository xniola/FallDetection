1) Struttura dataset: immagine.jpg --> annotazioni.csv (immagine.jpg,[1-0]) 0: not fall, 1: fall
  - Quindi per ogni immagine del dataset abbiamo un record nel file csv in cui viene scritto se quell'immagine corrisponde ad una caduta o meno.

2) Ur Fall Detection Dataset:
  - Scaricate le 30 sequenze di fall (train_images) e le 40 di adl (adl-all-cam0-rgb) 
  - Per ogni sequenza di fall e adl sono state scritte le annotazioni in csv (rispettivamente fall-csv e adl-csv)
  - Creato file unico train_labels.csv contenente tutte le annotazioni in fall-csv
  - creato file train_labels.csv contenente le annotazioni delle 30 sequenze di fall
  - Uso 27 sequenze di fall per training (train_images), 2 per il test (seq.29,30 test_images), 1 per validation (colab)
  - Aggiungo la sequenza 2 e 11 di cam1 (depth camera) alle immagini di training (con relative annotazioni) 
  - Aggiungo parti delle sequenze  3,4,17,21,24 di cam1(depth camera) alle immagini di test (con relative annotazioni)

3) Risultati
  1) Fallnet: 
     6 epoche -> 95%
     15 epoche -> 98.8%
     28 epoche -> 95.2%
     50 epoche -> 94.6%


TODO: Cross validation (pesco diversi test set alla volta)

